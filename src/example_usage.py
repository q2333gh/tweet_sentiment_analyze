"""
ä½¿ç”¨ç¤ºä¾‹è„šæœ¬ - å±•ç¤ºå¦‚ä½•ä½¿ç”¨å„ä¸ªæ¨¡å—
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def example_single_module():
    """ç¤ºä¾‹ï¼šè¿è¡Œå•ä¸ªæ¨¡å—"""
    print("=" * 60)
    print("ç¤ºä¾‹1: è¿è¡Œå•ä¸ªæ¨¡å—")
    print("=" * 60)
    
    # ç¤ºä¾‹ï¼šæ•°æ®æå–
    print("\n1. æ•°æ®æå–ç¤ºä¾‹:")
    print("```python")
    print("from src.data_extraction import extract_ten_percent_sample")
    print("")
    print("# æå–10%æ ·æœ¬æ•°æ®")
    print("success = extract_ten_percent_sample()")
    print("print(f'æ•°æ®æå–æˆåŠŸ: {success}')")
    print("```")
    
    # ç¤ºä¾‹ï¼šæƒ…æ„Ÿåˆ†æ
    print("\n2. æƒ…æ„Ÿåˆ†æç¤ºä¾‹:")
    print("```python")
    print("from src.sentiment_analysis import analyze_sentiment")
    print("")
    print("# æ‰§è¡Œæƒ…æ„Ÿåˆ†æ")
    print("report = analyze_sentiment()")
    print("if report.get('success'):")
    print("    print('æƒ…æ„Ÿåˆ†æå®Œæˆï¼')")
    print("    dist = report.get('sentiment_distribution', {})")
    print("    if dist and 'distribution' in dist:")
    print("        print('æƒ…æ„Ÿåˆ†å¸ƒ:')")
    print("        for _, row in dist['distribution'].iterrows():")
    print("            print(f'  {row["sentiment_category"]}: {row["count"]:,}')")
    print("```")

def example_full_pipeline():
    """ç¤ºä¾‹ï¼šè¿è¡Œå®Œæ•´æµæ°´çº¿"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2: è¿è¡Œå®Œæ•´æµæ°´çº¿")
    print("=" * 60)
    
    print("\nä½¿ç”¨Pipelineç±»:")
    print("```python")
    print("from src.main import TweetSentimentAnalysisPipeline")
    print("")
    print("# åˆ›å»ºæµæ°´çº¿å®ä¾‹")
    print("pipeline = TweetSentimentAnalysisPipeline()")
    print("")
    print("# è¿è¡Œå®Œæ•´æµæ°´çº¿")
    print("final_report = pipeline.run_full_pipeline()")
    print("")
    print("# æŸ¥çœ‹ç»“æœ")
    print("if final_report['pipeline_summary']['success_rate'] > 80:")
    print("    print('æµæ°´çº¿æ‰§è¡ŒæˆåŠŸï¼')")
    print("    print(f'æˆåŠŸç‡: {final_report["pipeline_summary"]["success_rate"]:.1f}%')")
    print("    ")
    print("    # æŸ¥çœ‹å…³é”®æŒ‡æ ‡")
    print("    metrics = final_report.get('key_metrics', {})")
    print("    if 'best_model' in metrics:")
    print("        best = metrics['best_model']")
    print("        print(f'æœ€ä½³æ¨¡å‹: {best["name"]} (å‡†ç¡®ç‡: {best["accuracy"]:.4f})')")
    print("```")

def example_step_by_step():
    """ç¤ºä¾‹ï¼šé€æ­¥æ‰§è¡Œ"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3: é€æ­¥æ‰§è¡Œæµæ°´çº¿")
    print("=" * 60)
    
    print("\n```python")
    print("from src.main import TweetSentimentAnalysisPipeline")
    print("")
    print("# åˆ›å»ºæµæ°´çº¿å®ä¾‹")
    print("pipeline = TweetSentimentAnalysisPipeline()")
    print("")
    print("# é€æ­¥æ‰§è¡Œ")
    print("print('æ­¥éª¤1: æ•°æ®æå–')")
    print("success1 = pipeline.run_data_extraction()")
    print("")
    print("print('æ­¥éª¤2: æ•°æ®æ‘„å–åˆ†æ')")
    print("success2 = pipeline.run_data_ingestion()")
    print("")
    print("print('æ­¥éª¤3: æ•°æ®æ¸…æ´—')")
    print("success3 = pipeline.run_data_cleaning()")
    print("")
    print("print('æ­¥éª¤4: æƒ…æ„Ÿåˆ†æ')")
    print("success4 = pipeline.run_sentiment_analysis()")
    print("")
    print("print('æ­¥éª¤5: ä¸»é¢˜å»ºæ¨¡')")
    print("success5 = pipeline.run_topic_modeling()")
    print("")
    print("print('æ­¥éª¤6: åˆ†ç±»å»ºæ¨¡')")
    print("success6 = pipeline.run_classification()")
    print("")
    print("# æ£€æŸ¥æ‰€æœ‰æ­¥éª¤æ˜¯å¦æˆåŠŸ")
    print("all_success = all([success1, success2, success3, success4, success5, success6])")
    print("print(f'æ‰€æœ‰æ­¥éª¤å®Œæˆ: {all_success}')")
    print("```")

def example_command_line():
    """ç¤ºä¾‹ï¼šå‘½ä»¤è¡Œä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4: å‘½ä»¤è¡Œä½¿ç”¨")
    print("=" * 60)
    
    print("\n1. è¿è¡Œå®Œæ•´æµæ°´çº¿:")
    print("```bash")
    print("python -m src.main --step all")
    print("```")
    
    print("\n2. è¿è¡Œå•ä¸ªæ­¥éª¤:")
    print("```bash")
    print("# æ•°æ®æå–")
    print("python -m src.main --step extraction")
    print("")
    print("# æƒ…æ„Ÿåˆ†æ")
    print("python -m src.main --step sentiment")
    print("")
    print("# ä¸»é¢˜å»ºæ¨¡")
    print("python -m src.main --step topic")
    print("")
    print("# åˆ†ç±»å»ºæ¨¡")
    print("python -m src.main --step classification")
    print("```")
    
    print("\n3. è·³è¿‡æŸäº›æ­¥éª¤:")
    print("```bash")
    print("# è·³è¿‡æ•°æ®æå–å’Œæ‘„å–ï¼Œä»æ¸…æ´—å¼€å§‹")
    print("python -m src.main --step all --skip data_extraction data_ingestion")
    print("```")

def example_configuration():
    """ç¤ºä¾‹ï¼šé…ç½®è‡ªå®šä¹‰å‚æ•°"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹5: è‡ªå®šä¹‰é…ç½®")
    print("=" * 60)
    
    print("\nä¿®æ”¹config.pyä¸­çš„å‚æ•°:")
    print("```python")
    print("# ä¿®æ”¹æ•°æ®å¤„ç†å‚æ•°")
    print("DATA_PROCESSING = {")
    print("    'sample_fraction': 0.05,  # æ”¹ä¸º5%æ ·æœ¬")
    print("    'random_state': 42,")
    print("    'min_text_length': 20,    # å¢åŠ æœ€å°æ–‡æœ¬é•¿åº¦")
    print("    'min_tokens': 10,         # å¢åŠ æœ€å°è¯æ±‡æ•°")
    print("    'vocab_size': 5000,       # å¢åŠ è¯æ±‡è¡¨å¤§å°")
    print("    'min_doc_freq': 5.0")
    print("}")
    print("")
    print("# ä¿®æ”¹ä¸»é¢˜å»ºæ¨¡å‚æ•°")
    print("TOPIC_MODELING = {")
    print("    'num_topics': 10,         # å¢åŠ ä¸»é¢˜æ•°é‡")
    print("    'max_iterations': 20,     # å¢åŠ è¿­ä»£æ¬¡æ•°")
    print("    'vocab_size': 3000,")
    print("    'min_doc_freq': 15.0,")
    print("    'sample_fraction': 0.5,   # å¢åŠ é‡‡æ ·æ¯”ä¾‹")
    print("    'max_terms_per_topic': 20")
    print("}")
    print("```")

def example_error_handling():
    """ç¤ºä¾‹ï¼šé”™è¯¯å¤„ç†"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹6: é”™è¯¯å¤„ç†")
    print("=" * 60)
    
    print("\n```python")
    print("from src.sentiment_analysis import analyze_sentiment")
    print("import logging")
    print("")
    print("# è®¾ç½®æ—¥å¿—çº§åˆ«")
    print("logging.basicConfig(level=logging.INFO)")
    print("")
    print("try:")
    print("    # æ‰§è¡Œæƒ…æ„Ÿåˆ†æ")
    print("    report = analyze_sentiment()")
    print("    ")
    print("    if report.get('success', False):")
    print("        print('âœ… æƒ…æ„Ÿåˆ†ææˆåŠŸå®Œæˆ')")
    print("        # å¤„ç†ç»“æœ...")
    print("    else:")
    print("        print('âŒ æƒ…æ„Ÿåˆ†æå¤±è´¥')")
    print("        error_msg = report.get('error', 'æœªçŸ¥é”™è¯¯')")
    print("        print(f'é”™è¯¯ä¿¡æ¯: {error_msg}')")
    print("        ")
    print("except Exception as e:")
    print("    print(f'æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {str(e)}')")
    print("    # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯")
    print("    import traceback")
    print("    traceback.print_exc()")
    print("```")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Tweetæƒ…æ„Ÿåˆ†ææ¨¡å—ä½¿ç”¨ç¤ºä¾‹")
    print("æœ¬è„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å„ä¸ªæ¨¡å—è¿›è¡Œæƒ…æ„Ÿåˆ†æ")
    
    # æ˜¾ç¤ºæ‰€æœ‰ç¤ºä¾‹
    example_single_module()
    example_full_pipeline()
    example_step_by_step()
    example_command_line()
    example_configuration()
    example_error_handling()
    
    print("\n" + "=" * 60)
    print("ğŸ“š æ›´å¤šä¿¡æ¯")
    print("=" * 60)
    print("- è¯¦ç»†æ–‡æ¡£: src/README.md")
    print("- é…ç½®æ–‡ä»¶: src/config.py")
    print("- æµ‹è¯•è„šæœ¬: src/test_imports.py")
    print("- ä¸»è¿è¡Œè„šæœ¬: src/main.py")
    
    print("\nğŸ’¡ æç¤º:")
    print("1. è¿è¡Œå‰è¯·ç¡®ä¿å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
    print("2. æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹config.pyä¸­çš„æ•°æ®è·¯å¾„")
    print("3. ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†…å­˜è¿è¡ŒSpark (å»ºè®®16GB+)")
    print("4. å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—è¾“å‡ºè·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 