# Tweetæƒ…æ„Ÿåˆ†æPythonæ¨¡å—

æœ¬ç›®å½•åŒ…å«äº†ä»Jupyter notebooksè½¬æ¢è€Œæ¥çš„Pythonæ¨¡å—ï¼Œå®ç°äº†å®Œæ•´çš„Tweetæƒ…æ„Ÿåˆ†ææµæ°´çº¿ã€‚

## æ¨¡å—ç»“æ„

```
src/
â”œâ”€â”€ __init__.py              # åŒ…åˆå§‹åŒ–æ–‡ä»¶
â”œâ”€â”€ config.py                # é…ç½®æ–‡ä»¶
â”œâ”€â”€ utils.py                 # é€šç”¨å·¥å…·å‡½æ•°
â”œâ”€â”€ data_extraction.py       # æ•°æ®æå–æ¨¡å— (å¯¹åº” 0_extract_ten_percent.ipynb)
â”œâ”€â”€ data_ingestion.py        # æ•°æ®æ‘„å–å’Œç»Ÿè®¡åˆ†æ (å¯¹åº” 1_data_ingestion_and_stats.ipynb)
â”œâ”€â”€ data_cleaning.py         # æ•°æ®æ¸…æ´—æ¨¡å— (å¯¹åº” 2_data_cleaning.ipynb)
â”œâ”€â”€ sentiment_analysis.py    # æƒ…æ„Ÿåˆ†ææ¨¡å— (å¯¹åº” 3_eda_and_sentiment_analysis.ipynb)
â”œâ”€â”€ topic_modeling.py        # ä¸»é¢˜å»ºæ¨¡æ¨¡å— (å¯¹åº” 4_topic_modeling_lda.ipynb)
â”œâ”€â”€ classification.py        # åˆ†ç±»å»ºæ¨¡æ¨¡å— (å¯¹åº” 5_classification_modeling.ipynb)
â”œâ”€â”€ main.py                  # ä¸»è¿è¡Œè„šæœ¬
â””â”€â”€ README.md               # æœ¬æ–‡æ¡£
```

## åŠŸèƒ½ç‰¹æ€§

### ğŸ”§ æ ¸å¿ƒåŠŸèƒ½
- **æ•°æ®æå–**: ä»åŸå§‹æ•°æ®ä¸­æå–10%æ ·æœ¬
- **æ•°æ®æ‘„å–**: åŸºæœ¬ç»Ÿè®¡åˆ†æå’Œæ•°æ®æ¢ç´¢
- **æ•°æ®æ¸…æ´—**: æ–‡æœ¬æ¸…æ´—ã€å»é‡ã€åˆ†è¯ã€åœç”¨è¯å¤„ç†
- **æƒ…æ„Ÿåˆ†æ**: ä½¿ç”¨VADERè¿›è¡Œæƒ…æ„Ÿåˆ†æå’Œåˆ†ç±»
- **ä¸»é¢˜å»ºæ¨¡**: ä½¿ç”¨LDAè¿›è¡Œä¸»é¢˜å‘ç°
- **åˆ†ç±»å»ºæ¨¡**: æœ´ç´ è´å¶æ–¯å’Œéšæœºæ£®æ—åˆ†ç±»å™¨

### ğŸš€ æŠ€æœ¯æ ˆ
- **å¤§æ•°æ®å¤„ç†**: PySpark
- **æœºå™¨å­¦ä¹ **: PySpark MLlib + scikit-learn
- **æƒ…æ„Ÿåˆ†æ**: VADER Sentiment
- **å¯è§†åŒ–**: matplotlib + seaborn + wordcloud
- **æ•°æ®å­˜å‚¨**: Parquetæ ¼å¼

## å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

## ä½¿ç”¨æ–¹æ³•

### 1. è¿è¡Œå®Œæ•´æµæ°´çº¿

```python
from src.main import TweetSentimentAnalysisPipeline

# åˆ›å»ºæµæ°´çº¿å®ä¾‹
pipeline = TweetSentimentAnalysisPipeline()

# è¿è¡Œå®Œæ•´æµæ°´çº¿
final_report = pipeline.run_full_pipeline()
```

### 2. è¿è¡Œå•ä¸ªæ¨¡å—

#### æ•°æ®æå–
```python
from src.data_extraction import extract_ten_percent_sample

# æå–10%æ ·æœ¬æ•°æ®
success = extract_ten_percent_sample()
```

#### æ•°æ®æ‘„å–åˆ†æ
```python
from src.data_ingestion import analyze_data_ingestion

# æ‰§è¡Œæ•°æ®æ‘„å–åˆ†æ
report = analyze_data_ingestion(use_sample=True, save_plots=True)
```

#### æ•°æ®æ¸…æ´—
```python
from src.data_cleaning import clean_data

# æ‰§è¡Œæ•°æ®æ¸…æ´—
report = clean_data()
```

#### æƒ…æ„Ÿåˆ†æ
```python
from src.sentiment_analysis import analyze_sentiment

# æ‰§è¡Œæƒ…æ„Ÿåˆ†æ
report = analyze_sentiment()
```

#### ä¸»é¢˜å»ºæ¨¡
```python
from src.topic_modeling import perform_topic_modeling

# æ‰§è¡Œä¸»é¢˜å»ºæ¨¡
report = perform_topic_modeling()
```

#### åˆ†ç±»å»ºæ¨¡
```python
from src.classification import perform_classification

# æ‰§è¡Œåˆ†ç±»å»ºæ¨¡
report = perform_classification()
```

### 3. å‘½ä»¤è¡Œä½¿ç”¨

```bash
# è¿è¡Œå®Œæ•´æµæ°´çº¿
python -m src.main --step all

# è¿è¡Œå•ä¸ªæ­¥éª¤
python -m src.main --step extraction
python -m src.main --step ingestion
python -m src.main --step cleaning
python -m src.main --step sentiment
python -m src.main --step topic
python -m src.main --step classification

# è·³è¿‡æŸäº›æ­¥éª¤
python -m src.main --step all --skip data_extraction data_ingestion
```

## é…ç½®è¯´æ˜

ä¸»è¦é…ç½®åœ¨ `config.py` ä¸­å®šä¹‰ï¼š

```python
# æ•°æ®è·¯å¾„é…ç½®
DATA_PATHS = {
    'raw_data': '/path/to/raw/data.csv',
    'processed_dir': '/path/to/processed/',
    # ...
}

# å¤„ç†å‚æ•°
DATA_PROCESSING = {
    'sample_fraction': 0.1,
    'random_state': 42,
    'min_text_length': 10,
    # ...
}

# æƒ…æ„Ÿåˆ†æå‚æ•°
SENTIMENT_CONFIG = {
    'positive_threshold': 0.05,
    'negative_threshold': -0.05,
    # ...
}

# ä¸»é¢˜å»ºæ¨¡å‚æ•°
TOPIC_MODELING = {
    'num_topics': 5,
    'max_iterations': 10,
    # ...
}
```

## è¾“å‡ºæ–‡ä»¶

æµæ°´çº¿æ‰§è¡Œåä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
data/processed/
â”œâ”€â”€ the-reddit-climate-change-dataset-comments-ten-percent.parquet  # 10%æ ·æœ¬æ•°æ®
â”œâ”€â”€ cleaned_comments.parquet                                        # æ¸…æ´—åæ•°æ®
â”œâ”€â”€ sentiment_analyzed_comments.parquet                             # æƒ…æ„Ÿåˆ†æç»“æœ
â””â”€â”€ topic_analyzed_comments.parquet                                # ä¸»é¢˜åˆ†æç»“æœ
```

## å¯è§†åŒ–è¾“å‡º

å„æ¨¡å—ä¼šç”Ÿæˆä»¥ä¸‹å¯è§†åŒ–å›¾è¡¨ï¼š

- **æ•°æ®æ‘„å–**: å­ç‰ˆå—åˆ†æå›¾ã€æƒ…æ„Ÿåˆ†å¸ƒå›¾ã€æ–‡æœ¬é•¿åº¦åˆ†å¸ƒå›¾
- **æƒ…æ„Ÿåˆ†æ**: æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾ã€å­ç‰ˆå—æƒ…æ„Ÿåˆ†æå›¾ã€è¯é¢‘åˆ†æå›¾ã€è¯äº‘å›¾
- **ä¸»é¢˜å»ºæ¨¡**: ä¸»é¢˜å…³é”®è¯å›¾ã€ä¸»é¢˜åˆ†å¸ƒå›¾ã€ä¸»é¢˜è¯äº‘å›¾ã€ä¸»é¢˜-æƒ…æ„Ÿçƒ­åŠ›å›¾
- **åˆ†ç±»å»ºæ¨¡**: æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾ã€æ··æ·†çŸ©é˜µ

## é”™è¯¯å¤„ç†

æ‰€æœ‰æ¨¡å—éƒ½åŒ…å«å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼š

- è‡ªåŠ¨æ£€æµ‹æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- æä¾›å¤‡é€‰æ•°æ®æº
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—è®°å½•
- ä¼˜é›…çš„èµ„æºæ¸…ç†

## æ€§èƒ½ä¼˜åŒ–

- ä½¿ç”¨PySparkè¿›è¡Œåˆ†å¸ƒå¼è®¡ç®—
- æ•°æ®ç¼“å­˜ç­–ç•¥
- é‡‡æ ·ç­–ç•¥å‡å°‘è®¡ç®—è´Ÿæ‹…
- Parquetæ ¼å¼æé«˜I/Oæ€§èƒ½

## æ‰©å±•æ€§

æ¨¡å—è®¾è®¡å…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§ï¼š

- å¯ä»¥è½»æ¾æ·»åŠ æ–°çš„åˆ†ææ¨¡å—
- æ”¯æŒè‡ªå®šä¹‰é…ç½®å‚æ•°
- æ¨¡å—é—´æ¾è€¦åˆè®¾è®¡
- æ”¯æŒä¸åŒçš„æ•°æ®æºæ ¼å¼

## æ³¨æ„äº‹é¡¹

1. **å†…å­˜è¦æ±‚**: å»ºè®®è‡³å°‘16GBå†…å­˜ç”¨äºSparkè®¡ç®—
2. **æ•°æ®è·¯å¾„**: è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ `config.py` ä¸­çš„è·¯å¾„é…ç½®
3. **ä¾èµ–å®‰è£…**: ç¡®ä¿æ‰€æœ‰ä¾èµ–åº“æ­£ç¡®å®‰è£…
4. **Javaç¯å¢ƒ**: PySparkéœ€è¦Java 8+ç¯å¢ƒ

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Spark Sessionåˆ›å»ºå¤±è´¥**
   - æ£€æŸ¥Javaç¯å¢ƒæ˜¯å¦æ­£ç¡®å®‰è£…
   - æ£€æŸ¥å†…å­˜é…ç½®æ˜¯å¦å……è¶³

2. **æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°**
   - æ£€æŸ¥ `config.py` ä¸­çš„è·¯å¾„é…ç½®
   - ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨ä¸”æœ‰è¯»å–æƒé™

3. **å†…å­˜ä¸è¶³é”™è¯¯**
   - å‡å°‘ `sample_fraction` å‚æ•°
   - è°ƒæ•´Sparkå†…å­˜é…ç½®

4. **ä¾èµ–åº“å¯¼å…¥é”™è¯¯**
   - é‡æ–°å®‰è£… requirements.txt ä¸­çš„ä¾èµ–
   - æ£€æŸ¥Pythonç¯å¢ƒæ˜¯å¦æ­£ç¡®

## è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚ 