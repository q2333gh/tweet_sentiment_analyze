{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ç¬¬äº”æ­¥ï¼šåˆ†ç±»å»ºæ¨¡ (Classification Modeling)\n",
        "\n",
        "## æœ¬notebookçš„ç›®æ ‡ï¼š\n",
        "1. åŠ è½½ç»è¿‡æƒ…æ„Ÿåˆ†æå’Œä¸»é¢˜å»ºæ¨¡çš„æ•°æ®\n",
        "2. å‡†å¤‡ç‰¹å¾å·¥ç¨‹ï¼ˆæ–‡æœ¬å‘é‡åŒ–å’Œä¸»é¢˜åˆ†å¸ƒç‰¹å¾ï¼‰\n",
        "3. è®­ç»ƒåˆ†ç±»æ¨¡å‹ï¼ˆNaive Bayes å’Œ Random Forestï¼‰\n",
        "4. æ¨¡å‹è¯„ä¼°å’Œæ¯”è¾ƒ\n",
        "5. ç”Ÿæˆæ¨¡å‹è¯„ä¼°æŠ¥å‘Š\n",
        "\n",
        "## åˆ†ç±»ä»»åŠ¡\n",
        "- **ç›®æ ‡å˜é‡**: æƒ…æ„Ÿæ ‡ç­¾ï¼ˆç§¯æã€ä¸­æ€§ã€æ¶ˆæï¼‰\n",
        "- **ç‰¹å¾**: TF-IDFå‘é‡ + ä¸»é¢˜åˆ†å¸ƒ\n",
        "- **æ¨¡å‹**: Naive Bayesã€Random Forest\n",
        "- **è¯„ä¼°æŒ‡æ ‡**: å‡†ç¡®ç‡ã€å¬å›ç‡ã€F1å€¼ã€æ··æ·†çŸ©é˜µ\n",
        "\n",
        "## æ¨¡å‹æµç¨‹\n",
        "1. æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹\n",
        "2. è®­ç»ƒ/æµ‹è¯•é›†åˆ’åˆ†\n",
        "3. æ¨¡å‹è®­ç»ƒå’Œè°ƒå‚\n",
        "4. æ¨¡å‹è¯„ä¼°å’Œå¯¹æ¯”\n",
        "5. ç‰¹å¾é‡è¦æ€§åˆ†æ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "åº“å¯¼å…¥å®Œæˆï¼\n"
          ]
        }
      ],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.feature import VectorAssembler, StringIndexer, IndexToString\n",
        "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# è®¾ç½®å›¾è¡¨æ ·å¼\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"åº“å¯¼å…¥å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark Version: 3.5.0\n",
            "Available cores: 20\n"
          ]
        }
      ],
      "source": [
        "# åˆå§‹åŒ–Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"TweetAnalysis_Classification\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.memory\", \"16g\") \\\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(f\"Spark Version: {spark.version}\")\n",
        "print(f\"Available cores: {spark.sparkContext.defaultParallelism}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== æ•°æ®åŠ è½½ ===\n",
            "âŒ æ•°æ®åŠ è½½å¤±è´¥: [PATH_NOT_FOUND] Path does not exist: file:/home/jovyan/work/data/processed/topic_analyzed_comments.parquet.\n",
            "ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ...\n",
            "âœ… ä½¿ç”¨æ¸…æ´—åæ•°æ®ï¼Œå…± 459,171 æ¡è®°å½•\n"
          ]
        }
      ],
      "source": [
        "# åŠ è½½ä¸»é¢˜åˆ†æå’Œæƒ…æ„Ÿåˆ†æçš„æ•°æ®\n",
        "print(\"=== æ•°æ®åŠ è½½ ===\")\n",
        "\n",
        "# å°è¯•åŠ è½½ä¸»é¢˜åˆ†æç»“æœ\n",
        "topic_data_path = \"/home/jovyan/work/data/processed/topic_analyzed_comments.parquet\"\n",
        "\n",
        "try:\n",
        "    df_topic = spark.read.parquet(topic_data_path)\n",
        "    df_topic.cache()\n",
        "    record_count = df_topic.count()\n",
        "    print(f\"âœ… ä¸»é¢˜åˆ†ææ•°æ®åŠ è½½å®Œæˆï¼Œå…± {record_count:,} æ¡è®°å½•\")\n",
        "    \n",
        "    print(\"\\næ•°æ®ç»“æ„:\")\n",
        "    df_topic.printSchema()\n",
        "    \n",
        "    # æ£€æŸ¥å¿…è¦çš„åˆ—\n",
        "    required_cols = ['sentiment_label', 'cleaned_body', 'dominant_topic']\n",
        "    missing_cols = [col for col in required_cols if col not in df_topic.columns]\n",
        "    \n",
        "    if missing_cols:\n",
        "        print(f\"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}\")\n",
        "        print(\"å°è¯•åŠ è½½å…¶ä»–æ•°æ®æº...\")\n",
        "        \n",
        "        # å¤‡é€‰æ–¹æ¡ˆï¼šåŠ è½½æƒ…æ„Ÿåˆ†ææ•°æ®\n",
        "        sentiment_data_path = \"/home/jovyan/work/data/processed/sentiment_analyzed_comments.parquet\"\n",
        "        df_sentiment = spark.read.parquet(sentiment_data_path)\n",
        "        \n",
        "        # éœ€è¦é‡æ–°è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»\n",
        "        def classify_sentiment(score):\n",
        "            if score is None:\n",
        "                return \"æœªçŸ¥\"\n",
        "            elif score > 0.1:\n",
        "                return \"ç§¯æ\"\n",
        "            elif score < -0.1:\n",
        "                return \"æ¶ˆæ\"\n",
        "            else:\n",
        "                return \"ä¸­æ€§\"\n",
        "        \n",
        "        classify_sentiment_udf = F.udf(classify_sentiment, StringType())\n",
        "        \n",
        "        # æ‰¾åˆ°æƒ…æ„Ÿåˆ†æ•°åˆ—\n",
        "        sentiment_col = None\n",
        "        for col in ['compound_score', 'vader_compound', 'sentiment']:\n",
        "            if col in df_sentiment.columns:\n",
        "                sentiment_col = col\n",
        "                break\n",
        "        \n",
        "        if sentiment_col:\n",
        "            df_topic = df_sentiment.withColumn(\n",
        "                \"sentiment_label\",\n",
        "                classify_sentiment_udf(F.col(sentiment_col))\n",
        "            )\n",
        "            df_topic = df_topic.withColumn(\"dominant_topic\", F.lit(0))  # ä¸´æ—¶ä¸»é¢˜\n",
        "            record_count = df_topic.count()\n",
        "            print(f\"âœ… ä½¿ç”¨æƒ…æ„Ÿåˆ†ææ•°æ®ï¼Œå…± {record_count:,} æ¡è®°å½•\")\n",
        "        else:\n",
        "            raise Exception(\"æœªæ‰¾åˆ°æƒ…æ„Ÿåˆ†æ•°åˆ—\")\n",
        "    else:\n",
        "        print(\"âœ… æ‰€æœ‰å¿…è¦åˆ—éƒ½å­˜åœ¨\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}\")\n",
        "    print(\"ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ...\")\n",
        "    \n",
        "    # æœ€åå¤‡é€‰ï¼šä½¿ç”¨æ¸…æ´—åçš„æ•°æ®\n",
        "    cleaned_data_path = \"/home/jovyan/work/data/processed/cleaned_comments.parquet\"\n",
        "    df_base = spark.read.parquet(cleaned_data_path)\n",
        "    \n",
        "    # ä½¿ç”¨åŸå§‹sentimentåˆ—\n",
        "    def classify_sentiment(score):\n",
        "        if score is None:\n",
        "            return \"æœªçŸ¥\"\n",
        "        elif score > 0.1:\n",
        "            return \"ç§¯æ\"\n",
        "        elif score < -0.1:\n",
        "            return \"æ¶ˆæ\"\n",
        "        else:\n",
        "            return \"ä¸­æ€§\"\n",
        "    \n",
        "    classify_sentiment_udf = F.udf(classify_sentiment, StringType())\n",
        "    \n",
        "    df_topic = df_base.withColumn(\n",
        "        \"sentiment_label\",\n",
        "        classify_sentiment_udf(F.col(\"sentiment\"))\n",
        "    ).withColumn(\"dominant_topic\", F.lit(0))  # ä¸´æ—¶ä¸»é¢˜\n",
        "    \n",
        "    record_count = df_topic.count()\n",
        "    print(f\"âœ… ä½¿ç”¨æ¸…æ´—åæ•°æ®ï¼Œå…± {record_count:,} æ¡è®°å½•\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹ ===\n",
            "1. æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ:\n",
            "+---------------+------+\n",
            "|sentiment_label| count|\n",
            "+---------------+------+\n",
            "|           æ¶ˆæ|205850|\n",
            "|           ç§¯æ|201235|\n",
            "|           ä¸­æ€§| 47179|\n",
            "|           æœªçŸ¥|  4907|\n",
            "+---------------+------+\n",
            "\n",
            "è¯¦ç»†åˆ†å¸ƒ:\n",
            "  æ¶ˆæ: 205,850 (44.83%)\n",
            "  ç§¯æ: 201,235 (43.83%)\n",
            "  ä¸­æ€§: 47,179 (10.27%)\n",
            "  æœªçŸ¥: 4,907 (1.07%)\n",
            "\n",
            "è¿‡æ»¤åæ•°æ®é‡: 454,264 æ¡è®°å½•\n",
            "3. âœ… å·²æœ‰åˆ†è¯ç»“æœ\n",
            "\n",
            "æœ€ç»ˆç”¨äºå»ºæ¨¡çš„æ•°æ®: 454,264 æ¡è®°å½•\n"
          ]
        }
      ],
      "source": [
        "# æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹\n",
        "print(\"=== æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹ ===\")\n",
        "\n",
        "# 1. æ£€æŸ¥æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ\n",
        "print(\"1. æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ:\")\n",
        "sentiment_dist = df_topic.groupBy(\"sentiment_label\").count().orderBy(F.desc(\"count\"))\n",
        "sentiment_dist.show()\n",
        "\n",
        "# è½¬æ¢ä¸ºpandasæŸ¥çœ‹è¯¦ç»†æ¯”ä¾‹\n",
        "sentiment_dist_pd = sentiment_dist.toPandas()\n",
        "total_count = sentiment_dist_pd['count'].sum()\n",
        "sentiment_dist_pd['percentage'] = (sentiment_dist_pd['count'] / total_count * 100).round(2)\n",
        "\n",
        "print(\"è¯¦ç»†åˆ†å¸ƒ:\")\n",
        "for _, row in sentiment_dist_pd.iterrows():\n",
        "    label = row['sentiment_label']\n",
        "    count = int(row['count'])\n",
        "    pct = row['percentage']\n",
        "    print(f\"  {label}: {count:,} ({pct}%)\")\n",
        "\n",
        "# 2. è¿‡æ»¤æ‰\"æœªçŸ¥\"æ ‡ç­¾çš„æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
        "df_filtered = df_topic.filter(F.col(\"sentiment_label\") != \"æœªçŸ¥\")\n",
        "filtered_count = df_filtered.count()\n",
        "print(f\"\\nè¿‡æ»¤åæ•°æ®é‡: {filtered_count:,} æ¡è®°å½•\")\n",
        "\n",
        "# 3. æ£€æŸ¥æ˜¯å¦æœ‰åˆ†è¯ç»“æœï¼Œå¦‚æœæ²¡æœ‰åˆ™é‡æ–°åˆ†è¯\n",
        "if 'tokens_cleaned' not in df_filtered.columns:\n",
        "    print(\"3. é‡æ–°è¿›è¡Œæ–‡æœ¬åˆ†è¯...\")\n",
        "    from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
        "    \n",
        "    # åˆ†è¯\n",
        "    tokenizer = Tokenizer(inputCol=\"cleaned_body\", outputCol=\"tokens_raw\")\n",
        "    df_tokens = tokenizer.transform(df_filtered)\n",
        "    \n",
        "    # å»åœç”¨è¯\n",
        "    remover = StopWordsRemover(inputCol=\"tokens_raw\", outputCol=\"tokens_cleaned\")\n",
        "    df_filtered = remover.transform(df_tokens)\n",
        "    print(\"   åˆ†è¯å®Œæˆ\")\n",
        "else:\n",
        "    print(\"3. âœ… å·²æœ‰åˆ†è¯ç»“æœ\")\n",
        "\n",
        "print(f\"\\næœ€ç»ˆç”¨äºå»ºæ¨¡çš„æ•°æ®: {df_filtered.count():,} æ¡è®°å½•\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== æ„å»ºç‰¹å¾å‘é‡ ===\n",
            "1. æ„å»ºTF-IDFç‰¹å¾...\n",
            "   TF-IDFè¯æ±‡è¡¨å¤§å°: 3000\n",
            "2. æ·»åŠ ä¸»é¢˜ç‰¹å¾...\n"
          ]
        },
        {
          "ename": "IllegalArgumentException",
          "evalue": "requirement failed: The input column topic_index should have at least two distinct values.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# One-hotç¼–ç \u001b[39;00m\n\u001b[1;32m     39\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(inputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_indexed\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(df_indexed)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# åˆå¹¶TF-IDFå’Œä¸»é¢˜ç‰¹å¾\u001b[39;00m\n\u001b[1;32m     43\u001b[0m assembler \u001b[38;5;241m=\u001b[39m VectorAssembler(\n\u001b[1;32m     44\u001b[0m     inputCols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtfidf_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic_features\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     45\u001b[0m     outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
            "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m/usr/local/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: The input column topic_index should have at least two distinct values."
          ]
        }
      ],
      "source": [
        "# æ„å»ºç‰¹å¾å‘é‡\n",
        "print(\"=== æ„å»ºç‰¹å¾å‘é‡ ===\")\n",
        "\n",
        "from pyspark.ml.feature import CountVectorizer, IDF\n",
        "\n",
        "# 1. æ–‡æœ¬ç‰¹å¾ï¼šTF-IDFå‘é‡åŒ–\n",
        "print(\"1. æ„å»ºTF-IDFç‰¹å¾...\")\n",
        "\n",
        "# CountVectorizer\n",
        "count_vectorizer = CountVectorizer(\n",
        "    inputCol=\"tokens_cleaned\", \n",
        "    outputCol=\"raw_features\",\n",
        "    vocabSize=3000,  # å‡å°‘ç‰¹å¾ç»´åº¦æé«˜è®­ç»ƒé€Ÿåº¦\n",
        "    minDF=3.0        # æœ€å°æ–‡æ¡£é¢‘ç‡\n",
        ")\n",
        "\n",
        "count_model = count_vectorizer.fit(df_filtered)\n",
        "df_vectorized = count_model.transform(df_filtered)\n",
        "\n",
        "# TF-IDF\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf_features\")\n",
        "idf_model = idf.fit(df_vectorized)\n",
        "df_tfidf = idf_model.transform(df_vectorized)\n",
        "\n",
        "print(f\"   TF-IDFè¯æ±‡è¡¨å¤§å°: {len(count_model.vocabulary)}\")\n",
        "\n",
        "# 2. ä¸»é¢˜ç‰¹å¾ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰\n",
        "if 'dominant_topic' in df_tfidf.columns:\n",
        "    print(\"2. æ·»åŠ ä¸»é¢˜ç‰¹å¾...\")\n",
        "    # å°†ä¸»é¢˜IDè½¬æ¢ä¸ºone-hotç¼–ç \n",
        "    from pyspark.ml.feature import OneHotEncoder\n",
        "    \n",
        "    # å…ˆè½¬æ¢ä¸ºæ•°å€¼ç´¢å¼•\n",
        "    indexer = StringIndexer(inputCol=\"dominant_topic\", outputCol=\"topic_index\")\n",
        "    indexer_model = indexer.fit(df_tfidf)\n",
        "    df_indexed = indexer_model.transform(df_tfidf)\n",
        "    \n",
        "    # One-hotç¼–ç \n",
        "    encoder = OneHotEncoder(inputCol=\"topic_index\", outputCol=\"topic_features\")\n",
        "    df_encoded = encoder.fit(df_indexed).transform(df_indexed)\n",
        "    \n",
        "    # åˆå¹¶TF-IDFå’Œä¸»é¢˜ç‰¹å¾\n",
        "    assembler = VectorAssembler(\n",
        "        inputCols=[\"tfidf_features\", \"topic_features\"],\n",
        "        outputCol=\"features\"\n",
        "    )\n",
        "    df_features = assembler.transform(df_encoded)\n",
        "    print(\"   âœ… TF-IDF + ä¸»é¢˜ç‰¹å¾åˆå¹¶å®Œæˆ\")\n",
        "else:\n",
        "    print(\"2. ä»…ä½¿ç”¨TF-IDFç‰¹å¾...\")\n",
        "    df_features = df_tfidf.withColumnRenamed(\"tfidf_features\", \"features\")\n",
        "\n",
        "print(f\"æœ€ç»ˆç‰¹å¾æ•°æ®: {df_features.count():,} æ¡è®°å½•\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å‡†å¤‡è®­ç»ƒæ•°æ®å’Œæ ‡ç­¾ç¼–ç \n",
        "print(\"=== å‡†å¤‡è®­ç»ƒæ•°æ® ===\")\n",
        "\n",
        "# 1. å°†æƒ…æ„Ÿæ ‡ç­¾è½¬æ¢ä¸ºæ•°å€¼ç´¢å¼•\n",
        "label_indexer = StringIndexer(inputCol=\"sentiment_label\", outputCol=\"label\")\n",
        "indexer_model = label_indexer.fit(df_features)\n",
        "df_labeled = indexer_model.transform(df_features)\n",
        "\n",
        "# è·å–æ ‡ç­¾æ˜ å°„\n",
        "labels = indexer_model.labels\n",
        "print(f\"æ ‡ç­¾æ˜ å°„: {dict(enumerate(labels))}\")\n",
        "\n",
        "# 2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
        "print(\"2. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†...\")\n",
        "train_data, test_data = df_labeled.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "train_count = train_data.count()\n",
        "test_count = test_data.count()\n",
        "\n",
        "print(f\"è®­ç»ƒé›†: {train_count:,} æ¡è®°å½•\")\n",
        "print(f\"æµ‹è¯•é›†: {test_count:,} æ¡è®°å½•\")\n",
        "\n",
        "# ç¼“å­˜æ•°æ®æé«˜åç»­è®­ç»ƒé€Ÿåº¦\n",
        "train_data.cache()\n",
        "test_data.cache()\n",
        "\n",
        "# 3. æ£€æŸ¥è®­ç»ƒé›†ä¸­çš„æ ‡ç­¾åˆ†å¸ƒ\n",
        "print(\"\\n3. è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ:\")\n",
        "train_label_dist = train_data.groupBy(\"sentiment_label\").count().orderBy(F.desc(\"count\"))\n",
        "train_label_dist.show()\n",
        "\n",
        "print(\"æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ:\")\n",
        "test_label_dist = test_data.groupBy(\"sentiment_label\").count().orderBy(F.desc(\"count\"))\n",
        "test_label_dist.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è®­ç»ƒNaive Bayesæ¨¡å‹\n",
        "print(\"=== è®­ç»ƒNaive Bayesæ¨¡å‹ ===\")\n",
        "\n",
        "# 1. åˆ›å»ºNaive Bayesåˆ†ç±»å™¨\n",
        "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\", predictionCol=\"nb_prediction\")\n",
        "\n",
        "print(\"1. å¼€å§‹è®­ç»ƒNaive Bayesæ¨¡å‹...\")\n",
        "nb_model = nb.fit(train_data)\n",
        "print(\"   âœ… Naive Bayesè®­ç»ƒå®Œæˆ\")\n",
        "\n",
        "# 2. åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹\n",
        "print(\"2. åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹...\")\n",
        "nb_predictions = nb_model.transform(test_data)\n",
        "\n",
        "# 3. è¯„ä¼°Naive Bayesæ¨¡å‹\n",
        "print(\"3. è¯„ä¼°Naive Bayesæ¨¡å‹:\")\n",
        "\n",
        "# å‡†ç¡®ç‡\n",
        "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"nb_prediction\", metricName=\"accuracy\"\n",
        ")\n",
        "nb_accuracy = evaluator_accuracy.evaluate(nb_predictions)\n",
        "\n",
        "# F1åˆ†æ•°\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"nb_prediction\", metricName=\"f1\"\n",
        ")\n",
        "nb_f1 = evaluator_f1.evaluate(nb_predictions)\n",
        "\n",
        "# åŠ æƒç²¾ç¡®ç‡\n",
        "evaluator_precision = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"nb_prediction\", metricName=\"weightedPrecision\"\n",
        ")\n",
        "nb_precision = evaluator_precision.evaluate(nb_predictions)\n",
        "\n",
        "# åŠ æƒå¬å›ç‡\n",
        "evaluator_recall = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"nb_prediction\", metricName=\"weightedRecall\"\n",
        ")\n",
        "nb_recall = evaluator_recall.evaluate(nb_predictions)\n",
        "\n",
        "print(f\"   å‡†ç¡®ç‡: {nb_accuracy:.4f}\")\n",
        "print(f\"   F1åˆ†æ•°: {nb_f1:.4f}\")\n",
        "print(f\"   åŠ æƒç²¾ç¡®ç‡: {nb_precision:.4f}\")\n",
        "print(f\"   åŠ æƒå¬å›ç‡: {nb_recall:.4f}\")\n",
        "\n",
        "# ä¿å­˜Naive Bayesç»“æœ\n",
        "nb_results = {\n",
        "    'model': 'Naive Bayes',\n",
        "    'accuracy': nb_accuracy,\n",
        "    'f1': nb_f1,\n",
        "    'precision': nb_precision,\n",
        "    'recall': nb_recall\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è®­ç»ƒRandom Forestæ¨¡å‹\n",
        "print(\"=== è®­ç»ƒRandom Forestæ¨¡å‹ ===\")\n",
        "\n",
        "# 1. åˆ›å»ºRandom Foreståˆ†ç±»å™¨\n",
        "rf = RandomForestClassifier(\n",
        "    featuresCol=\"features\", \n",
        "    labelCol=\"label\", \n",
        "    predictionCol=\"rf_prediction\",\n",
        "    numTrees=50,        # æ ‘çš„æ•°é‡ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´\n",
        "    maxDepth=10,        # æœ€å¤§æ·±åº¦\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(\"1. å¼€å§‹è®­ç»ƒRandom Forestæ¨¡å‹...\")\n",
        "rf_model = rf.fit(train_data)\n",
        "print(\"   âœ… Random Forestè®­ç»ƒå®Œæˆ\")\n",
        "\n",
        "# 2. åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹\n",
        "print(\"2. åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹...\")\n",
        "rf_predictions = rf_model.transform(test_data)\n",
        "\n",
        "# 3. è¯„ä¼°Random Forestæ¨¡å‹\n",
        "print(\"3. è¯„ä¼°Random Forestæ¨¡å‹:\")\n",
        "\n",
        "# å‡†ç¡®ç‡\n",
        "rf_accuracy = evaluator_accuracy.setParams(predictionCol=\"rf_prediction\").evaluate(rf_predictions)\n",
        "\n",
        "# F1åˆ†æ•°\n",
        "rf_f1 = evaluator_f1.setParams(predictionCol=\"rf_prediction\").evaluate(rf_predictions)\n",
        "\n",
        "# åŠ æƒç²¾ç¡®ç‡\n",
        "rf_precision = evaluator_precision.setParams(predictionCol=\"rf_prediction\").evaluate(rf_predictions)\n",
        "\n",
        "# åŠ æƒå¬å›ç‡\n",
        "rf_recall = evaluator_recall.setParams(predictionCol=\"rf_prediction\").evaluate(rf_predictions)\n",
        "\n",
        "print(f\"   å‡†ç¡®ç‡: {rf_accuracy:.4f}\")\n",
        "print(f\"   F1åˆ†æ•°: {rf_f1:.4f}\")\n",
        "print(f\"   åŠ æƒç²¾ç¡®ç‡: {rf_precision:.4f}\")\n",
        "print(f\"   åŠ æƒå¬å›ç‡: {rf_recall:.4f}\")\n",
        "\n",
        "# ä¿å­˜Random Forestç»“æœ\n",
        "rf_results = {\n",
        "    'model': 'Random Forest',\n",
        "    'accuracy': rf_accuracy,\n",
        "    'f1': rf_f1,\n",
        "    'precision': rf_precision,\n",
        "    'recall': rf_recall\n",
        "}\n",
        "\n",
        "# 4. ç‰¹å¾é‡è¦æ€§åˆ†æ\n",
        "print(\"\\n4. ç‰¹å¾é‡è¦æ€§åˆ†æ:\")\n",
        "feature_importances = rf_model.featureImportances\n",
        "print(f\"ç‰¹å¾é‡è¦æ€§å‘é‡é•¿åº¦: {len(feature_importances)}\")\n",
        "\n",
        "# è·å–æœ€é‡è¦çš„ç‰¹å¾ï¼ˆå¦‚æœæ˜¯æ–‡æœ¬ç‰¹å¾ï¼‰\n",
        "if len(feature_importances) > 0:\n",
        "    # è½¬æ¢ä¸ºpandasè¿›è¡Œåˆ†æ\n",
        "    importance_array = feature_importances.toArray()\n",
        "    \n",
        "    # å¦‚æœç‰¹å¾ä¸»è¦æ˜¯è¯æ±‡ç‰¹å¾ï¼Œæ˜¾ç¤ºæœ€é‡è¦çš„è¯æ±‡\n",
        "    vocab_size = len(count_model.vocabulary)\n",
        "    if vocab_size <= len(importance_array):\n",
        "        word_importance = [(count_model.vocabulary[i], importance_array[i]) \n",
        "                          for i in range(min(vocab_size, len(importance_array)))]\n",
        "        word_importance.sort(key=lambda x: x[1], reverse=True)\n",
        "        \n",
        "        print(\"   æœ€é‡è¦çš„10ä¸ªè¯æ±‡ç‰¹å¾:\")\n",
        "        for word, importance in word_importance[:10]:\n",
        "            print(f\"     {word}: {importance:.6f}\")\n",
        "    \n",
        "    print(f\"   ç‰¹å¾é‡è¦æ€§æ€»å’Œ: {sum(importance_array):.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ¨¡å‹æ¯”è¾ƒå’Œè¯„ä¼°æŠ¥å‘Š\n",
        "print(\"=== æ¨¡å‹æ¯”è¾ƒå’Œè¯„ä¼°æŠ¥å‘Š ===\")\n",
        "\n",
        "# 1. æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ\n",
        "results_comparison = pd.DataFrame([nb_results, rf_results])\n",
        "print(\"1. æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ:\")\n",
        "print(results_comparison.round(4))\n",
        "\n",
        "# 2. å¯è§†åŒ–æ¨¡å‹æ¯”è¾ƒ\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "metrics = ['accuracy', 'f1', 'precision', 'recall']\n",
        "metric_names = ['å‡†ç¡®ç‡', 'F1åˆ†æ•°', 'åŠ æƒç²¾ç¡®ç‡', 'åŠ æƒå¬å›ç‡']\n",
        "\n",
        "for i, (metric, name) in enumerate(zip(metrics, metric_names)):\n",
        "    ax = axes[i//2, i%2]\n",
        "    \n",
        "    values = [nb_results[metric], rf_results[metric]]\n",
        "    models = ['Naive Bayes', 'Random Forest']\n",
        "    colors = ['lightblue', 'lightgreen']\n",
        "    \n",
        "    bars = ax.bar(models, values, color=colors, alpha=0.8)\n",
        "    ax.set_title(f'{name}æ¯”è¾ƒ', fontweight='bold')\n",
        "    ax.set_ylabel(name)\n",
        "    ax.set_ylim(0, 1)\n",
        "    \n",
        "    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾\n",
        "    for bar, value in zip(bars, values):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# 3. ç¡®å®šæœ€ä½³æ¨¡å‹\n",
        "best_model_name = 'Naive Bayes' if nb_f1 > rf_f1 else 'Random Forest'\n",
        "best_predictions = nb_predictions if nb_f1 > rf_f1 else rf_predictions\n",
        "best_pred_col = 'nb_prediction' if nb_f1 > rf_f1 else 'rf_prediction'\n",
        "\n",
        "print(f\"\\n3. æœ€ä½³æ¨¡å‹: {best_model_name} (F1åˆ†æ•°: {max(nb_f1, rf_f1):.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Šå’Œæ··æ·†çŸ©é˜µ\n",
        "print(\"=== è¯¦ç»†åˆ†ç±»æŠ¥å‘Š ===\")\n",
        "\n",
        "# 1. ç”Ÿæˆæ··æ·†çŸ©é˜µæ•°æ®\n",
        "def get_confusion_matrix_data(predictions, prediction_col):\n",
        "    \"\"\"ç”Ÿæˆæ··æ·†çŸ©é˜µæ•°æ®\"\"\"\n",
        "    # æ”¶é›†é¢„æµ‹ç»“æœ\n",
        "    results = predictions.select(\"label\", prediction_col).collect()\n",
        "    \n",
        "    y_true = [row[\"label\"] for row in results]\n",
        "    y_pred = [row[prediction_col] for row in results]\n",
        "    \n",
        "    return y_true, y_pred\n",
        "\n",
        "# 2. ä¸ºæœ€ä½³æ¨¡å‹ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š\n",
        "print(f\"ä¸ºæœ€ä½³æ¨¡å‹ ({best_model_name}) ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š:\")\n",
        "\n",
        "y_true, y_pred = get_confusion_matrix_data(best_predictions, best_pred_col)\n",
        "\n",
        "# è½¬æ¢æ•°å€¼æ ‡ç­¾å›æ–‡å­—æ ‡ç­¾\n",
        "label_mapping = {i: label for i, label in enumerate(labels)}\n",
        "y_true_labels = [label_mapping[int(label)] for label in y_true]\n",
        "y_pred_labels = [label_mapping[int(pred)] for pred in y_pred]\n",
        "\n",
        "# ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"\\n1. åˆ†ç±»æŠ¥å‘Š:\")\n",
        "print(classification_report(y_true_labels, y_pred_labels, zero_division=0))\n",
        "\n",
        "# 2. æ··æ·†çŸ©é˜µ\n",
        "print(\"2. æ··æ·†çŸ©é˜µ:\")\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels, labels=labels)\n",
        "print(cm)\n",
        "\n",
        "# 3. å¯è§†åŒ–æ··æ·†çŸ©é˜µ\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.title(f'{best_model_name} - æ··æ·†çŸ©é˜µ', fontweight='bold')\n",
        "plt.xlabel('é¢„æµ‹æ ‡ç­¾')\n",
        "plt.ylabel('çœŸå®æ ‡ç­¾')\n",
        "plt.show()\n",
        "\n",
        "# 4. æŒ‰ç±»åˆ«åˆ†ææ€§èƒ½\n",
        "print(\"\\n3. å„ç±»åˆ«æ€§èƒ½åˆ†æ:\")\n",
        "for i, label in enumerate(labels):\n",
        "    true_positives = cm[i, i]\n",
        "    false_positives = sum(cm[:, i]) - true_positives\n",
        "    false_negatives = sum(cm[i, :]) - true_positives\n",
        "    \n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    \n",
        "    print(f\"  {label}:\")\n",
        "    print(f\"    ç²¾ç¡®ç‡: {precision:.4f}\")\n",
        "    print(f\"    å¬å›ç‡: {recall:.4f}\")\n",
        "    print(f\"    F1åˆ†æ•°: {f1:.4f}\")\n",
        "    print(f\"    æ”¯æŒæ ·æœ¬æ•°: {sum(cm[i, :])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¿å­˜æ¨¡å‹è¯„ä¼°ç»“æœ\n",
        "print(\"=== ä¿å­˜æ¨¡å‹è¯„ä¼°ç»“æœ ===\")\n",
        "\n",
        "# 1. åˆ›å»ºå®Œæ•´çš„è¯„ä¼°æŠ¥å‘Š\n",
        "evaluation_report = {\n",
        "    \"experiment_info\": {\n",
        "        \"dataset_size\": df_filtered.count(),\n",
        "        \"train_size\": train_count,\n",
        "        \"test_size\": test_count,\n",
        "        \"feature_size\": len(count_model.vocabulary),\n",
        "        \"num_classes\": len(labels),\n",
        "        \"class_labels\": labels\n",
        "    },\n",
        "    \"models\": {\n",
        "        \"naive_bayes\": nb_results,\n",
        "        \"random_forest\": rf_results\n",
        "    },\n",
        "    \"best_model\": {\n",
        "        \"name\": best_model_name,\n",
        "        \"metrics\": nb_results if best_model_name == 'Naive Bayes' else rf_results\n",
        "    },\n",
        "    \"class_distribution\": {\n",
        "        \"train\": train_label_dist.toPandas().to_dict('records'),\n",
        "        \"test\": test_label_dist.toPandas().to_dict('records')\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. ä¿å­˜è¯„ä¼°æŠ¥å‘Š\n",
        "import json\n",
        "report_path = \"/home/jovyan/work/data/processed/classification_evaluation_report.json\"\n",
        "\n",
        "with open(report_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(evaluation_report, f, ensure_ascii=False, indent=2, default=str)\n",
        "\n",
        "print(f\"âœ… æ¨¡å‹è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}\")\n",
        "\n",
        "# 3. ä¿å­˜æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ç»“æœï¼ˆæ ·æœ¬ï¼‰\n",
        "sample_predictions = best_predictions.select(\n",
        "    \"id\", \"cleaned_body\", \"sentiment_label\", \"label\", best_pred_col\n",
        ").limit(1000)\n",
        "\n",
        "sample_path = \"/home/jovyan/work/data/processed/classification_sample_predictions.parquet\"\n",
        "sample_predictions.write.mode(\"overwrite\").parquet(sample_path)\n",
        "\n",
        "print(f\"âœ… æ ·æœ¬é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {sample_path}\")\n",
        "\n",
        "# 4. ç”Ÿæˆæœ€ç»ˆæ€»ç»“\n",
        "print(\"\\n=== åˆ†ç±»å»ºæ¨¡æ€»ç»“ ===\")\n",
        "print(f\"ğŸ¯ å®éªŒå®Œæˆæ¦‚å†µ:\")\n",
        "print(f\"   æ•°æ®é›†å¤§å°: {df_filtered.count():,} æ¡è®°å½•\")\n",
        "print(f\"   ç‰¹å¾ç»´åº¦: {len(count_model.vocabulary):,}\")\n",
        "print(f\"   ç±»åˆ«æ•°é‡: {len(labels)}\")\n",
        "print(f\"   è®­ç»ƒé›†: {train_count:,} | æµ‹è¯•é›†: {test_count:,}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”:\")\n",
        "print(f\"   Naive Bayes    - å‡†ç¡®ç‡: {nb_accuracy:.4f} | F1: {nb_f1:.4f}\")\n",
        "print(f\"   Random Forest  - å‡†ç¡®ç‡: {rf_accuracy:.4f} | F1: {rf_f1:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name}\")\n",
        "best_metrics = nb_results if best_model_name == 'Naive Bayes' else rf_results\n",
        "print(f\"   å‡†ç¡®ç‡: {best_metrics['accuracy']:.4f}\")\n",
        "print(f\"   F1åˆ†æ•°: {best_metrics['f1']:.4f}\")\n",
        "print(f\"   ç²¾ç¡®ç‡: {best_metrics['precision']:.4f}\")\n",
        "print(f\"   å¬å›ç‡: {best_metrics['recall']:.4f}\")\n",
        "\n",
        "print(f\"\\nğŸ’¡ ç»“æœåˆ†æ:\")\n",
        "if best_metrics['accuracy'] > 0.7:\n",
        "    print(\"   âœ… æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œå¯ä»¥è¾ƒå¥½åœ°åŒºåˆ†æƒ…æ„Ÿç±»åˆ«\")\n",
        "elif best_metrics['accuracy'] > 0.6:\n",
        "    print(\"   âš ï¸ æ¨¡å‹æ€§èƒ½ä¸­ç­‰ï¼Œæœ‰æ”¹è¿›ç©ºé—´\")\n",
        "else:\n",
        "    print(\"   âŒ æ¨¡å‹æ€§èƒ½è¾ƒä½ï¼Œå»ºè®®è°ƒæ•´ç‰¹å¾æˆ–ç®—æ³•\")\n",
        "\n",
        "print(f\"\\nğŸ”§ æ”¹è¿›å»ºè®®:\")\n",
        "print(\"   1. å¯ä»¥å°è¯•æ›´å¤šçš„ç‰¹å¾å·¥ç¨‹ï¼ˆå¦‚N-gramã€è¯å‘é‡ç­‰ï¼‰\")\n",
        "print(\"   2. è°ƒæ•´æ¨¡å‹è¶…å‚æ•°è¿›è¡Œä¼˜åŒ–\")\n",
        "print(\"   3. è€ƒè™‘é›†æˆå­¦ä¹ æ–¹æ³•\")\n",
        "print(\"   4. å¢åŠ æ›´å¤šçš„é¢„å¤„ç†æ­¥éª¤\")\n",
        "\n",
        "print(\"\\n=== åˆ†ç±»å»ºæ¨¡å®éªŒå®Œæˆï¼ ===\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
