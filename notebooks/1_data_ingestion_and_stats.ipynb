{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 第一步：数据加载与基本统计分析\n",
        "\n",
        "# 本 notebook 的目标：\n",
        "# 1. 初始化 Spark Session\n",
        "# 2. 加载原始数据\n",
        "# 3. 查看数据结构和基本信息\n",
        "# 4. 进行描述性统计分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import StringType\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 设置图表样式\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 初始化 Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"TweetAnalysis_DataIngestion\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.memory\", \"16g\") \\\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "print(f\"Spark Version: {spark.version}\")\n",
        "print(f\"Available cores: {sc.defaultParallelism}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载数据\n",
        "raw_data_path = \"/home/jovyan/work/data/raw/the-reddit-climate-change-dataset-comments.csv\"\n",
        "\n",
        "# 加载数据，让Spark自动推断Schema\n",
        "df_raw = spark.read.csv(raw_data_path, header=True, inferSchema=True, multiLine=True, escape='\"')\n",
        "\n",
        "# 缓存DataFrame，后续操作会更快\n",
        "df_raw.cache()\n",
        "\n",
        "print(\"数据加载完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 查看数据结构\n",
        "print(\"=== 数据结构 (Schema) ===\")\n",
        "df_raw.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 查看前几行数据\n",
        "print(\"=== 前5行数据 ===\")\n",
        "df_raw.show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 基本统计信息\n",
        "print(\"=== 基本统计信息 ===\")\n",
        "\n",
        "# 1. 数据总量\n",
        "total_count = df_raw.count()\n",
        "print(f\"总评论数量: {total_count:,}\")\n",
        "\n",
        "# 2. 列数\n",
        "num_columns = len(df_raw.columns)\n",
        "print(f\"列数: {num_columns}\")\n",
        "\n",
        "# 3. 列名\n",
        "print(f\"列名: {df_raw.columns}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 检查各列的详细信息和样本数据\n",
        "print(\"=== 各列详细信息 ===\")\n",
        "for col_name in df_raw.columns:\n",
        "    print(f\"\\n列名: {col_name}\")\n",
        "    print(f\"数据类型: {dict(df_raw.dtypes)[col_name]}\")\n",
        "    \n",
        "    # 显示非空值数量 - 使用反引号处理包含点号的列名\n",
        "    if '.' in col_name:\n",
        "        non_null_count = df_raw.filter(F.col(f\"`{col_name}`\").isNotNull()).count()\n",
        "    else:\n",
        "        non_null_count = df_raw.filter(F.col(col_name).isNotNull()).count()\n",
        "    \n",
        "    null_count = total_count - non_null_count\n",
        "    print(f\"非空值: {non_null_count:,} | 空值: {null_count:,} ({null_count/total_count*100:.2f}%)\")\n",
        "    \n",
        "    # 显示样本值（对于字符串类型，限制长度）\n",
        "    if col_name in ['body', 'permalink']:\n",
        "        sample_values = df_raw.select(col_name).limit(2).collect()\n",
        "        for i, row in enumerate(sample_values):\n",
        "            value = str(row[0])[:100] + \"...\" if row[0] and len(str(row[0])) > 100 else row[0]\n",
        "            print(f\"  样本{i+1}: {value}\")\n",
        "    else:\n",
        "        sample_values = df_raw.select(col_name).limit(3).collect()\n",
        "        for i, row in enumerate(sample_values):\n",
        "            print(f\"  样本{i+1}: {row[0]}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 时间范围分析\n",
        "print(\"=== 时间范围分析 ===\")\n",
        "\n",
        "# 转换时间戳为可读格式\n",
        "df_with_time = df_raw.withColumn(\"timestamp\", F.from_unixtime(F.col(\"created_utc\")))\n",
        "\n",
        "# 获取时间范围\n",
        "time_stats = df_with_time.select(\n",
        "    F.min(\"timestamp\").alias(\"earliest_time\"),\n",
        "    F.max(\"timestamp\").alias(\"latest_time\")\n",
        ").collect()[0]\n",
        "\n",
        "print(f\"最早评论时间: {time_stats['earliest_time']}\")\n",
        "print(f\"最晚评论时间: {time_stats['latest_time']}\")\n",
        "\n",
        "# 按年份统计评论数量\n",
        "yearly_stats = df_with_time.withColumn(\"year\", F.year(\"timestamp\")) \\\n",
        "                          .groupBy(\"year\") \\\n",
        "                          .count() \\\n",
        "                          .orderBy(\"year\")\n",
        "\n",
        "print(\"\\n按年份统计评论数量:\")\n",
        "yearly_stats.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 子版块分析\n",
        "print(\"=== 子版块分析 ===\")\n",
        "\n",
        "# 统计各子版块的评论数量 - 使用反引号处理列名\n",
        "subreddit_stats = df_raw.groupBy(F.col(\"`subreddit.name`\")) \\\n",
        "                        .count() \\\n",
        "                        .orderBy(F.desc(\"count\"))\n",
        "\n",
        "print(\"评论数量最多的前20个子版块:\")\n",
        "subreddit_stats.show(20)\n",
        "\n",
        "# 转换为 Pandas 进行可视化\n",
        "top_subreddits = subreddit_stats.limit(15).toPandas()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(data=top_subreddits, x='count', y='subreddit.name')\n",
        "plt.title('评论数量最多的前15个子版块')\n",
        "plt.xlabel('评论数量')\n",
        "plt.ylabel('子版块名称')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 情感分数分析（数据中已有sentiment列）\n",
        "print(\"=== 情感分数分析 ===\")\n",
        "\n",
        "# 基本统计\n",
        "sentiment_stats = df_raw.select(\"sentiment\").describe()\n",
        "sentiment_stats.show()\n",
        "\n",
        "# 情感分数分布\n",
        "print(\"情感分数分布:\")\n",
        "sentiment_ranges = df_raw.withColumn(\"sentiment_range\",\n",
        "    F.when(F.col(\"sentiment\") >= 0.1, \"positive\")\n",
        "     .when(F.col(\"sentiment\") <= -0.1, \"negative\")\n",
        "     .otherwise(\"neutral\")\n",
        ").groupBy(\"sentiment_range\").count().orderBy(F.desc(\"count\"))\n",
        "\n",
        "sentiment_ranges.show()\n",
        "\n",
        "# 可视化情感分数分布\n",
        "sentiment_sample = df_raw.select(\"sentiment\").sample(False, 0.01).toPandas()  # 抽样1%\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(sentiment_sample['sentiment'], bins=50, alpha=0.7, edgecolor='black')\n",
        "plt.title('情感分数分布直方图')\n",
        "plt.xlabel('情感分数')\n",
        "plt.ylabel('频次')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(y=sentiment_sample['sentiment'])\n",
        "plt.title('情感分数箱线图')\n",
        "plt.ylabel('情感分数')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 评论长度分析\n",
        "print(\"=== 评论长度分析 ===\")\n",
        "\n",
        "# 计算评论长度\n",
        "df_with_length = df_raw.withColumn(\"body_length\", F.length(F.col(\"body\")))\n",
        "\n",
        "# 长度统计\n",
        "length_stats = df_with_length.select(\"body_length\").describe()\n",
        "length_stats.show()\n",
        "\n",
        "# 长度分布\n",
        "print(\"评论长度分布:\")\n",
        "length_ranges = df_with_length.withColumn(\"length_range\",\n",
        "    F.when(F.col(\"body_length\") <= 50, \"very_short\")\n",
        "     .when(F.col(\"body_length\") <= 200, \"short\")\n",
        "     .when(F.col(\"body_length\") <= 500, \"medium\")\n",
        "     .when(F.col(\"body_length\") <= 1000, \"long\")\n",
        "     .otherwise(\"very_long\")\n",
        ").groupBy(\"length_range\").count().orderBy(F.desc(\"count\"))\n",
        "\n",
        "length_ranges.show()\n",
        "\n",
        "# 可视化评论长度分布\n",
        "length_sample = df_with_length.select(\"body_length\").sample(False, 0.01).toPandas()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(length_sample['body_length'], bins=50, alpha=0.7, edgecolor='black')\n",
        "plt.title('评论长度分布直方图')\n",
        "plt.xlabel('评论长度（字符数）')\n",
        "plt.ylabel('频次')\n",
        "plt.xlim(0, 2000)  # 限制x轴范围以便更好地观察\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "## 📊 数据探索总结\n",
        "\n",
        "通过以上分析，我们对数据集有了全面的了解：\n",
        "\n",
        "### 数据规模\n",
        "- **总量**: 460万条 Reddit 评论\n",
        "- **时间跨度**: 从数据中的时间戳可以看出覆盖的时间范围\n",
        "- **来源**: 多个 Reddit 子版块的气候变化相关讨论\n",
        "\n",
        "### 关键发现\n",
        "1. **数据质量**: 检查了各列的缺失值情况\n",
        "2. **情感分布**: 数据中已包含预计算的情感分数\n",
        "3. **内容长度**: 评论长度分布情况\n",
        "4. **社区分布**: 不同子版块的参与度\n",
        "\n",
        "### 下一步计划\n",
        "1. **数据清洗**: 处理缺失值、异常值和噪声数据\n",
        "2. **文本预处理**: 清理HTML标签、URL、特殊字符等\n",
        "3. **深度分析**: 情感趋势、主题建模、分类预测\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
