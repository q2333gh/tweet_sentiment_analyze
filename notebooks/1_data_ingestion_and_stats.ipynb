{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 第一步：数据加载与基本统计分析\n",
        "\n",
        "本 notebook 的目标：\n",
        "1. 初始化 Spark Session\n",
        "2. 加载原始数据\n",
        "3. 查看数据结构和基本信息\n",
        "4. 进行描述性统计分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import StringType\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 设置图表样式\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 初始化 Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"TweetAnalysis_DataIngestion\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.memory\", \"16g\") \\\n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "print(f\"Spark Version: {spark.version}\")\n",
        "print(f\"Available cores: {sc.defaultParallelism}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载数据\n",
        "raw_data_path = \"/home/jovyan/work/data/raw/the-reddit-climate-change-dataset-comments.csv\"\n",
        "\n",
        "# 加载数据，让Spark自动推断Schema\n",
        "df_raw = spark.read.csv(raw_data_path, header=True, inferSchema=True, multiLine=True, escape='\"')\n",
        "\n",
        "# 缓存DataFrame，后续操作会更快\n",
        "df_raw.cache()\n",
        "\n",
        "print(\"数据加载完成！\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 查看数据结构\n",
        "print(\"=== 数据结构 (Schema) ===\")\n",
        "df_raw.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 查看前几行数据\n",
        "print(\"=== 前5行数据 ===\")\n",
        "df_raw.show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 基本统计信息\n",
        "print(\"=== 基本统计信息 ===\")\n",
        "\n",
        "# 1. 数据总量\n",
        "total_count = df_raw.count()\n",
        "print(f\"总评论数量: {total_count:,}\")\n",
        "\n",
        "# 2. 列数\n",
        "num_columns = len(df_raw.columns)\n",
        "print(f\"列数: {num_columns}\")\n",
        "\n",
        "# 3. 列名\n",
        "print(f\"列名: {df_raw.columns}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
